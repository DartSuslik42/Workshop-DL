{"cells":[{"cell_type":"markdown","metadata":{"id":"E-vqHHuE_U5W"},"source":["# HW 1. Логистическая регрессия"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"3PhLKG01mF7y","executionInfo":{"status":"ok","timestamp":1754326166066,"user_tz":-120,"elapsed":3384,"user":{"displayName":"Egor Konyagin","userId":"14016957259147470680"}}},"outputs":[],"source":["import os\n","\n","import cv2\n","import numpy as np\n","from numpy.typing import NDArray\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n"]},{"cell_type":"markdown","metadata":{"id":"A6BdW91v_cNa"},"source":["## Загрузка данных\n","\n","Для того чтобы загрузить данные в нейросеть или более простые алгоритмы ML, их необходимо должным образом открыть и преобразовать в вектор с числами. Для этого воспользуемся функцией ```read_files()```.\n","\n","Этот парсер делает следующие вещи:\n"," - открывает файл картинки с диска (с помощью библиотеки opencv),\n"," - проверяет, что картинка действительно открылась и сейчас является матрицей (```np.array```),\n"," - преобразует матрицу в вектор (путем записи всех столбцов друг под другом),\n"," - возвращает массив из векторов, в которых хранятся картинки, и лейбл, соответствующий каждой картинке."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhJZszn4FAhG"},"outputs":[],"source":["def read_files(path: str, ans: int, target_dim: tuple = (256, 256)) -> dict[str, NDArray[np.float64]]:\n","    files = os.listdir(path)\n","    X = None\n","    for i, name in enumerate(files):\n","        img = cv2.imread(path + '/' + name, 0) # 0 means black-white picture\n","        if img.shape != 0:\n","            img = cv2.resize(img, target_dim, interpolation=cv2.INTER_LINEAR)\n","            vect = img.reshape(1, 256 ** 2) / 255.\n","\n","            X = vect if (X is None) else np.vstack((X, vect))\n","        # print(f\"{i}/{len(files)}\")\n","    # print()\n","    y = np.ones((len(files))) * ans\n","    return {\"data\": X, \"labels\": y}"]},{"cell_type":"code","source":["?np.vstack"],"metadata":{"id":"eXDrzYr-AY9a","executionInfo":{"status":"ok","timestamp":1754326485304,"user_tz":-120,"elapsed":22,"user":{"displayName":"Egor Konyagin","userId":"14016957259147470680"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n0Crs3tfd9OV"},"source":["Логика программы следующая:\n"," - есть класс ```LogisticRegression```. Он содержит веса модели и нужен для того, чтобы генерировать предсказания. Также, этот класс снабжен методом backward() для возможности дифференцирования функции потерь по весам этого класса.\n"," - есть класс ```Loss```. Он определяет функцию потерь, которую мы хотим использовать. Также, этот класс осуществляет подсчет градиентов функции потерь по всем весам модели.\n"," - есть класс ```Optimizer```. Он отвечает за то, как будут обновляться веса после подсчета градиентов (после работы класса ```Loss```). Сегодня мы рассматриваем простой градиентный спуск, но более сложные модели используют более усовершенствованные алгоритмы оптимизации.\n","\n","То есть:\n"," 1. Вызывается метод ```forward()``` нашей модели (логистической регрессии). После этого у нас выводятся текущие предсказания модели.\n"," 2. Вызывается метод ```loss()```, который сравнивает предсказания модели с истинными ответами. После этого подсчитываются градиенты функции потерь по всем весам модели.\n"," 3. Подсчитанные градиенты вычитаются из весов (происходит шаг градиентного спуска) путем вызова ```optimizer.step()```"]},{"cell_type":"markdown","metadata":{"id":"95y9pVGsNc0u"},"source":["## Логистическая регрессия. Backward propagation\n","Back propagation реализуется с помощью уравнений, написанных ниже. Для подсчитанной функции потерь:\n","$$\n","\\mathcal{L} = -\\frac{1}{m} \\sum_{i=1}^{m} y_i \\log(\\hat{y}_i) + (1 - y_i) \\log(1 - \\hat{y}_i)\n","$$\n","где $\\hat{y}_i = \\sigma(w^T x_i + b)$, где $\\sigma$ - сигмоидная функция.\n","\n","----Здесь необходимо провести расчеты для производных функции потерь по параметрам----"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sAgudbjuBzjo"},"outputs":[],"source":["class LogisticRegression:\n","    def __init__(self, n_features):\n","        \"\"\"Initialize model parameters with zeros.\"\"\"\n","        self.w = np.zeros(n_features)\n","        self.b = 0.0\n","\n","    def forward(self, X: NDArray[np.float64]) -> NDArray[np.float64]:\n","        \"\"\"Compute model predictions a.k.a. forward pass.\n","        Args:\n","            X: input data.\n","        Returns:\n","            probability predictions.\n","        \"\"\"\n","        z = np.dot(X, self.w) + self.b\n","        return self.sigmoid(z)\n","\n","    def sigmoid(self, z):\n","        return 1 / (1 + np.exp(-z))\n","\n","class Loss:\n","    def __init__(self):\n","        pass\n","\n","    def __call__(self, y_pred, y_true):\n","        eps= 1e-15  # Малое значение для предотвращения ошибок логарифма\n","        y_pred = np.clip(y_pred, eps, 1 - eps)  # Ограничение значений\n","        loss = - (y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n","        return np.mean(loss)\n","\n","    def backward(self, y_pred, y, X):\n","        pass\n","\n","class Optimizer:\n","    def __init__(self, learning_rate):\n","        self.learning_rate = learning_rate\n","\n","    def step(self, model, dw, db):\n","        model.w -= self.learning_rate * dw\n","        model.b -= self.learning_rate * db"]},{"cell_type":"markdown","metadata":{"id":"kH9cVot29-iu"},"source":["# Задание\n","\n","Дедлайн: чт 07.08 18:00 МСК\n","\n","1. Загрузить датасет, разбить его на два датасета: первый для обучения, второй - для проверки качества (см. функцию [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)) **(1 балл)**\n","2. Посчитать производные функции потерь по $w$ и по $b$ **(3 балла)**\n","3. Реализовать цикл обучения, обновляя параметры логистической регрессии. Необходим график зависимости от номера итерации **(5 баллов)**:\n","$$w = w - \\alpha \\cdot \\frac{\\partial L}{\\partial w}$$\n","<!-- <br> -->\n","$$b = b - \\alpha \\cdot \\frac{\\partial L}{\\partial b}$$\n","Обратите внимание на величину $\\alpha$. Ее надо подобрать, иначе алгоритм не будет обучаться.\n","\n","4. Посчитать качество модели по метрике [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) **(1 балл)**\n","\n","5. (бонус - оценивается только при успешном выполнении предыдущих пунктов) осуществить перебор по $\\alpha$ и найти его оптимальное значение (обеспечивающее максимальную метрику accuracy при достаточно небольшом количестве итераций обучения) **(2 балла)**"]},{"cell_type":"code","source":[],"metadata":{"id":"O5oXxpswDAk_"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.2"}},"nbformat":4,"nbformat_minor":0}