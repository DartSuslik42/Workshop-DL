{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-vqHHuE_U5W"
   },
   "source": [
    "# HW 2. –°–≤—ë—Ä—Ç–æ—á–Ω–∞—è –Ω–µ–π—Ä–æ–Ω–Ω–∞—è —Å–µ—Ç—å\n",
    "\n",
    "–Ω—É–∂–Ω–æ –≤–∑—è—Ç—å train —á–∞—Å—Ç—å –æ—Ç [tiny imagenet](http://cs231n.stanford.edu/tiny-imagenet-200.zip) dataset –∏ –æ–±—É—á–∏—Ç—å –õ–Æ–ë–£–Æ –Ω–µ–π—Ä–æ—Å–µ—Ç–∫—É\n",
    "\n",
    "üíÄ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è:  \n",
    "\\- –Ω–µ–ª—å–∑—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏  \n",
    "\\- –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏ –Ω–∞ –≤—Ö–æ–¥–µ 128—Ö128  \n",
    "\n",
    "—Ä–∞–∑–±–∞–ª–ª–æ–≤–∫–∞:  \n",
    "+üíé —É—Å–ø–µ—à–Ω–æ –Ω–∞–ø–∏—Å–∞–Ω –∫–ª–∞—Å—Å dataset –¥–ª—è tiny_imagenet. –ï—Å—Ç—å —Ä–∞–∑–±–∏–µ–Ω–∏–µ –Ω–∞ –¥–≤–µ —á–∞—Å—Ç–∏ (–æ–¥–Ω–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è, –≤—Ç–æ—Ä–∞—è –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏)  \n",
    "+üíé –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ albumentations –¥–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–æ–≤ dataset-a  \n",
    "+üíé —É—Å–ø–µ—à–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω –∞–ª–≥–æ—Ä–∏—Ç–º –æ–±—É—á–µ–Ω–∏—è –Ω–µ–π—Ä–æ—Å–µ—Ç–∏  \n",
    "+üíé accuracy in [45%, 55%)  \n",
    "+üíé accuracy >= 55%  \n",
    "Total: 5 / 5 üíé  \n",
    "\n",
    "–û—Ü–µ–Ω–∫–∞ accuracy –∏–¥—ë—Ç –ø–æ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏, –ø–æ—ç—Ç–æ–º—É –≤ git –Ω—É–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "BioR1xKZwgA1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import timm\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import cv2\n",
    "import albumentations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kOaQuPNJcHol"
   },
   "source": [
    "## –°–∫–∞—á–∏–≤–∞–µ–º dataset\n",
    "1. –ú–∞—É–Ω—Ç–∏–º Google-Drive –∫ Google-Colab\n",
    "2. –°–∫–∞—á–∏–≤–∞–µ–º –∏ —Ä–∞–∑–∞—Ä—Ö–∏–≤–∏—Ä—É–µ–º dataset –≤ Google-Drive\n",
    "3. –ß–∏—Å—Ç–∏–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "lpZ57cSasd8E"
   },
   "outputs": [],
   "source": [
    "DATASET_URL = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "DATASET_NAME = \"tiny-imagenet-200\"\n",
    "SAVE_PATH = \"\" # –≠—Ç–æ—Ç –ø—É—Ç—å —É–∂–µ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ google-drive\n",
    "DATASET_DIR = SAVE_PATH + DATASET_NAME\n",
    "NUM_CLASSES = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XPvXwcrNuU1M",
    "outputId": "bc61b5d9-9db4-40d7-afc2-943bfad4b265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device:cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"current device:{device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z0LSe4oHfqAk",
    "outputId": "9e511821-b569-4cc5-fa31-4095fa5f091c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-08-20 17:51:18--  http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
      "Resolving cs231n.stanford.edu (cs231n.stanford.edu)... 171.64.64.64\n",
      "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.64.64|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://cs231n.stanford.edu/tiny-imagenet-200.zip [following]\n",
      "--2025-08-20 17:51:19--  https://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
      "Connecting to cs231n.stanford.edu (cs231n.stanford.edu)|171.64.64.64|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 248100043 (237M) [application/zip]\n",
      "/content: Permission denied\n",
      "/content/tiny-imagenet-200.zip: No such file or directory\n",
      "\n",
      "Cannot write to ‚Äò/content/tiny-imagenet-200.zip‚Äô (Success).\n",
      "unzip:  cannot find or open /content/tiny-imagenet-200.zip, /content/tiny-imagenet-200.zip.zip or /content/tiny-imagenet-200.zip.ZIP.\n",
      "rm: cannot remove '/content/tiny-imagenet-200.zip': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ google colab\n",
    "!wget -P \"{SAVE_PATH}\" \"{DATASET_URL}\"\n",
    "!unzip -q \"{SAVE_PATH + DATASET_NAME + '.zip'}\" -d \"{SAVE_PATH}\"\n",
    "!rm -r \"{SAVE_PATH + DATASET_NAME + '.zip'}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4J0svRo6rPRr",
    "outputId": "53fecfc0-605a-43ce-a514-3d05bafe2b66"
   },
   "outputs": [],
   "source": [
    "# –ü–æ–¥–∫–ª—é—á–∞–µ–º Google Drive –¥–ª—è —Ä–µ–∑–µ—Ä–≤–Ω–æ–≥–æ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤ –º–æ–¥–µ–ª–∏\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "DRIVE_PATH = ''\n",
    "MODEL_FILENAME = \"model.pth\"\n",
    "LOG_FILENAME = 'training_log.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kn1BLY1JfREZ",
    "outputId": "658447c9-2c78-4080-bb56-d90dd8dfa1f5"
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è –≤ —Ñ–∞–π–ª. –ü–µ—á–∞—Ç–∞—Ç—å –≤ –∫–æ–Ω—Å–æ–ª—å = –ª–∞–≥–∏\n",
    "!rm \"{LOG_FILENAME}\"\n",
    "logging.basicConfig(\n",
    "    filename=LOG_FILENAME,\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(message)s',\n",
    "    datefmt='%H:%M:%S',\n",
    "    force=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A6BdW91v_cNa"
   },
   "source": [
    "## –ì–æ—Ç–æ–≤–∏–º dataset\n",
    "\n",
    "–ò—Å–ø–æ–ª—å–∑—É–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ tiny-imagenet-200 dataset:  \n",
    "- `words.txt` <small>*decoder: object id -> meaning*</small>  \n",
    "- `wnids.txt` <small>*object id's in curent dataset*</small>   \n",
    "- `train`   \n",
    "\n",
    "`train` —Å–æ–¥–µ—Ä–∂–∏—Ç –ø–∞–ø–∫–∏ —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º `[object id]` –∏–∑ `wnids.txt`.  \n",
    "–í–Ω—É—Ç—Ä–∏ –∫–∞–∂–¥–æ–π —Ç–∞–∫–æ–π –ø–∞–ø–∫–∏ –ª–µ–∂–∞—Ç:\n",
    "- –ø–∞–ø–∫–∞ `images` —Å–æ–¥–µ—Ä–∂–∞—â–∞—è –∫–∞—Ä—Ç–∏–Ω–∫–∏ `[object_id]_[picture_num].JPEG`\n",
    "- —Ñ–∞–π–ª –ª–µ–π–±–ª–æ–≤ `[object_id]_boxes.txt` —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è—é—â–∏–π –∫–∞–∂–¥–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–µ –∏–∑ `images` –Ω–µ–∫–æ—Ç–æ—Ä—ã–π bounding box.\n",
    "\n",
    "–í—Å–µ–≥–æ –≤ train dataset 200 –∫–ª–∞—Å—Å–æ–≤, ~100000 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSuFD6mOxyuJ"
   },
   "source": [
    "–ù–∞—á–Ω—ë–º —Å –ø–æ–ª—É—á–µ–Ω–∏—è —Å–ø–∏—Å–∫–∞ –≤—Å–µ—Ö –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –≤ –¥–∞—Ç–∞—Å–µ—Ç –∫–ª–∞—Å—Å–æ–≤. –ó–∞–ø–∏—Ö–Ω—ë–º –∏—Ö –≤ –º–∞—Å—Å–∏–≤ –∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AMZJ_A_ASwIb"
   },
   "outputs": [],
   "source": [
    "class ImgClass():\n",
    "  def __init__(self, name):\n",
    "    self.name = name # class id\n",
    "  def __str__(self):\n",
    "    return f\"{self.name}\"\n",
    "\n",
    "img_classes = np.empty(NUM_CLASSES, dtype=ImgClass)\n",
    "\n",
    "# img_classes init\n",
    "with open(os.path.join(DATASET_DIR, \"wnids.txt\"), \"r\") as f:\n",
    "  lines = sorted(f.readlines())\n",
    "  if len(lines) != NUM_CLASSES: raise SystemError(\"Not today\")\n",
    "  for idx, line in enumerate(lines):\n",
    "    class_id = line.strip()\n",
    "    img_classes[idx] = ImgClass(class_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yQ7wsnDIv6CQ"
   },
   "source": [
    "–°–æ–∑–¥–∞–¥–∏–º –∫–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö. –ö–ª–∞—Å—Å –±—É–¥–µ—Ç —Ä–∞–∑–±–∏–≤–∞—Ç—å tiny-image200 dataset –Ω–∞ 2 —á–∞—Å—Ç–∏ —Å —Ä–∞–∑–º–µ—Ä–æ–º –∑–∞–≤–∏—Å—è—â–∏–º –æ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏. –¢–∞–∫–∂–µ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —É –∫–ª–∞—Å—Å–∞ –æ—á–µ—Ä–µ–¥–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∫ –≤—ã–¥–∞–≤–∞–µ–º–æ–º—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –±—É–¥–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ –∞—É–≥—É–º–µ–Ω—Ç–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1_xoUZHoRoXr"
   },
   "outputs": [],
   "source": [
    "def get_class_img_dir(root_dir:str, img_class:str):\n",
    "  return os.path.join(root_dir, \"train\", img_class, \"images\")\n",
    "\n",
    "class DatasetCustom(torch.utils.data.Dataset):\n",
    "  def __init__(self,\n",
    "    transforms: albumentations.Compose | None,\n",
    "    train_split=0.9,\n",
    "    split_type='train',\n",
    "    root=DATASET_DIR,\n",
    "    ordered_classes=img_classes,\n",
    "  ):\n",
    "    self.files = []\n",
    "    self.labels = []\n",
    "    self.transforms = transforms\n",
    "\n",
    "    for img_class_idx, img_class in enumerate(ordered_classes):\n",
    "      # –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π –≤—Å–µ—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –∫–ª–∞—Å—Å–∞\n",
    "      class_img_path = get_class_img_dir(root, str(img_class))\n",
    "      class_images = sorted(os.listdir(class_img_path))\n",
    "\n",
    "      # —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –Ω–∞ 2 —á–∞—Å—Ç–∏: train + valid\n",
    "      valid_start_idx = int(len(class_images) * train_split)\n",
    "      if split_type == \"train\":\n",
    "        class_images = class_images[:valid_start_idx]\n",
    "      else:\n",
    "        class_images = class_images[valid_start_idx:]\n",
    "\n",
    "      # –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏–π —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π –∫ –∞–±—Å–æ–ª—é—Ç–Ω–æ–º—É –ø—É—Ç–∏\n",
    "      class_images = [\n",
    "        os.path.join(class_img_path, file_) for file_ in class_images\n",
    "      ]\n",
    "\n",
    "      # –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ –¥–∞—Ç–∞—Å–µ—Ç –ø—É—Ç–µ–π –∫ —Ñ–∞–π–ª–∞–º –∏ –ª—ç–π–±–ª–æ–≤\n",
    "      self.files.extend(class_images)\n",
    "      self.labels.extend([img_class_idx] * len(class_images))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.files)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    image = cv2.imread(self.files[idx])[:, :, ::-1]\n",
    "\n",
    "    if self.transforms is not None:\n",
    "      image = self.transforms(image=image)[\"image\"]\n",
    "    label = self.labels[idx]\n",
    "\n",
    "    return image, torch.tensor(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oQh3ZnJCAeK"
   },
   "source": [
    "–ó–∞–¥–∞–¥–∏–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è train + valid –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å–≤–∏–∏ —Å –¢–ó:\n",
    "\n",
    "- –ü—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—á–µ—Ä–µ–¥–Ω–æ–π –∫–∞—Ä—Ç–∏–Ω–∫–∏ –∏–∑ train-dataset –∫ –Ω–µ–π –±—É–¥–µ—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å—Å—è –∞—É–≥—É–º–µ–Ω—Ç–∞—Ü–∏—è. –ö–∞–∂–¥—É—é —ç–ø–æ—Ö—É –æ–¥–Ω–æ –∏ —Ç–æ–∂–µ train –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –±—É–¥–µ—Ç –ø–æ–¥–∞–≤–∞—Ç—å—Å—è —Å–æ —Å–ª—É—á–∞–π–Ω—ã–º –∏—Å–∫–∞–∂–µ–Ω–∏–µ–º.  \n",
    "\n",
    "- –ë—É–¥–µ–º –¥–µ–ª–∞—Ç—å resize 128x128  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vcoo6zzUwTfe",
    "outputId": "83f29125-0446-4bb2-f7ca-86a29d133ffb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikhail_m/.local/lib/python3.10/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_transform = albumentations.Compose(\n",
    "  [\n",
    "    # —Å–ª—É—á–∞–π–Ω–æ–µ –∏—Å—Å–∫–∞–∂–µ–Ω–∏–µ\n",
    "    albumentations.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
    "    # —Ç—è–∂—ë–ª—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏\n",
    "    albumentations.GaussianBlur(blur_limit=3, p=0.2), # –†–∞–∑–º—ã—Ç–∏–µ\n",
    "    albumentations.GaussNoise(p=0.2), # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —à—É–º–∞\n",
    "    # resize 128x128\n",
    "    albumentations.RandomResizedCrop((128,128)),\n",
    "    albumentations.CoarseDropout(\n",
    "        num_holes_range=(1,8),        \n",
    "        hole_height_range=(4,10),        \n",
    "        hole_width_range=(4,10),\n",
    "        fill=\"random\",\n",
    "        p=0.7),\n",
    "    albumentations.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.9),\n",
    "    albumentations.HorizontalFlip(p=0.5),\n",
    "    albumentations.VerticalFlip(p=0.3),\n",
    "    albumentations.ColorJitter(),\n",
    "    \n",
    "\n",
    "    # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    albumentations.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    albumentations.pytorch.ToTensorV2(),\n",
    "  ]\n",
    ")\n",
    "\n",
    "valid_transform = albumentations.Compose(\n",
    "  [\n",
    "    # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è\n",
    "    albumentations.Resize(height=128, width=128),\n",
    "    albumentations.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    albumentations.pytorch.ToTensorV2(),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OIvXckp0KleZ"
   },
   "source": [
    "–†–∞–∑–±–∏–≤–∞–µ–º –≤–µ—Å—å dataset –Ω–∞ 2 —á–∞—Å—Ç–∏: train + valid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "cH2EIc4rKlt4"
   },
   "outputs": [],
   "source": [
    "train_dataset = DatasetCustom(train_transform, split_type=\"train\", train_split=0.9)\n",
    "valid_dataset = DatasetCustom(valid_transform, split_type=\"valid\", train_split=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kNuMm_oSvEnz",
    "outputId": "e51b40d1-3c6d-4923-996a-f6c3f7388e8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.files), len(valid_dataset.files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YixLGpr4j9Sl"
   },
   "source": [
    "–°–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "EiLpNsJJMcw1"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    pin_memory=True,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Xk9tfF8J3Jm"
   },
   "source": [
    "–ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É **EfficientNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "POYlIRihuPFd"
   },
   "outputs": [],
   "source": [
    "model = timm.create_model(\n",
    "    'efficientnet_lite0',\n",
    "    pretrained=False,\n",
    "    in_chans=3,\n",
    "    num_classes=0,\n",
    "    global_pool=\"avg\",\n",
    "    drop_rate=0.3,\n",
    ")\n",
    "\n",
    "in_features = model.num_features\n",
    "out_features = in_features // 2\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "\n",
    "    torch.nn.Linear(\n",
    "      in_features=in_features,\n",
    "      out_features=out_features,\n",
    "      bias=False,\n",
    "    ),\n",
    "    torch.nn.BatchNorm1d(num_features=out_features),\n",
    "    torch.nn.ReLU6(inplace=True),\n",
    "\n",
    "    torch.nn.Linear(\n",
    "      in_features=out_features,\n",
    "      out_features=NUM_CLASSES,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "NoEzwgeumC9R"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-8)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yg4HSiM0zTbA",
    "outputId": "7b0ab49c-f652-497e-c3b2-d73aaf6c31dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded to cuda\n"
     ]
    }
   ],
   "source": [
    "# –∑–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "best_acc = 0.0\n",
    "MODEL_FILENAME = \"model_acc550.pth\"\n",
    "model_filename = os.path.join(DRIVE_PATH, MODEL_FILENAME)\n",
    "\n",
    "if False:\n",
    "  checkpoint = torch.load(\n",
    "      model_filename,\n",
    "      #MODEL_FILENAME,\n",
    "      map_location=torch.device(device)\n",
    "  )\n",
    "  model.load_state_dict(checkpoint['model_state_dict'])\n",
    "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "  best_acc = checkpoint['acc']\n",
    "  print(f\"Loaded model with acc: {best_acc}\")\n",
    "\n",
    "_ = model.to(device), print(f\"model loaded to {device}\")\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8LGjEeujOmmO"
   },
   "source": [
    "–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_used_mb():\n",
    "    free, total = torch.cuda.mem_get_info(device)\n",
    "    return (total - free) / 1024 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "DilkeRmYOmwv",
    "outputId": "4d0bc06b-b312-4b1a-dc2c-36820eebb7ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learing starting...\n",
      "Epoch 1/100 | train_loss=5.3753 | train_acc=0.005 | val_acc=0.007 | used GPU=13511.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikhail_m/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mikhail_m/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mikhail_m/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 | train_loss=5.3764 | train_acc=0.005 | val_acc=0.006 | used GPU=13511.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikhail_m/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mikhail_m/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mikhail_m/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 | train_loss=5.3777 | train_acc=0.005 | val_acc=0.006 | used GPU=13511.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikhail_m/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mikhail_m/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mikhail_m/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 | train_loss=5.3763 | train_acc=0.005 | val_acc=0.004 | used GPU=13511.0MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mikhail_m/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mikhail_m/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/home/mikhail_m/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m     45\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_pred, y)\n\u001b[0;32m---> 47\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     48\u001b[0m pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     49\u001b[0m correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (pred \u001b[38;5;241m==\u001b[39m y)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "N_EPOCH = 100\n",
    "total_steps = len(train_loader.dataset) // train_loader.batch_size + (1 if len(train_loader.dataset) % train_loader.batch_size != 0 else 0)\n",
    "\n",
    "# –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –æ—Ç–ª–æ–≤ –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è train_acc > val_acc\n",
    "MAX_TOLERANCE = 4\n",
    "MAX_TOLERANCE_DELTA = 0.1\n",
    "tolerance = 0\n",
    "\n",
    "# –æ—Ç–≤–µ—á–∞–µ—Ç –∑–∞ –æ—Ç–ª–æ–≤ —Å—Ç–∞–≥–Ω–∞—Ü–∏–∏ val_acc < best_val_acc\n",
    "MAX_PATIENCE = 4\n",
    "last_val_acc = 0.0\n",
    "patience = 0\n",
    "\n",
    "flag_rolledback = False # —Ñ–ª–∞–≥ –æ—Ç–∫–∞—Ç–∞ –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏ –Ω–∞ —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏\n",
    "flag_getbettermodel = False # —Ñ–ª–∞–≥ –ø–æ—è–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å –ª—É—á—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é\n",
    "\n",
    "total, correct = 0, 0\n",
    "total_loss, train_loss = 0.0, 0.0\n",
    "train_acc, val_acc = 0.0, 0.0\n",
    "\n",
    "try:\n",
    "  # main learn\n",
    "  logging.info(\"Learing starting...\")\n",
    "  print(\"Learing starting...\")\n",
    "  for epoch in range(N_EPOCH):\n",
    "    if flag_rolledback or flag_getbettermodel:\n",
    "        patience = 0\n",
    "        tolerance = 0\n",
    "        last_val_acc = 0.0\n",
    "        flag_rolledback = False\n",
    "        flag_getbettermodel = False\n",
    "        \n",
    "    # train\n",
    "    model.train()\n",
    "\n",
    "    total, correct, total_loss = 0, 0, 0.0\n",
    "\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "\n",
    "      optimizer.zero_grad(set_to_none=True)\n",
    "      x = x.to(device=device, non_blocking=True, dtype=torch.float32)\n",
    "      y = y.to(device=device, non_blocking=True, dtype=torch.long)\n",
    "\n",
    "      y_pred = model(x)\n",
    "      loss = criterion(y_pred, y)\n",
    "\n",
    "      total_loss += loss.item() * x.size(0)\n",
    "      pred = y_pred.argmax(1)\n",
    "      correct += (pred == y).sum().item()\n",
    "      total += x.size(0)\n",
    "\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      if step % 25 == 0:\n",
    "        logging.info(f\"{step+1}/{total_steps} | loss={loss.item():.4f} | acc={correct/total:.3f} \")\n",
    "\n",
    "    # train done\n",
    "    train_loss = total_loss / total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # valid\n",
    "    model.eval()\n",
    "\n",
    "    total, correct = 0, 0\n",
    "    ys = []\n",
    "    y_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for x, y in valid_loader:\n",
    "        x = x.to(device=device, non_blocking=True, dtype=torch.float32)\n",
    "        y = y.to(device=device, non_blocking=True, dtype=torch.long)\n",
    "\n",
    "        y_pred = model(x).argmax(1)\n",
    "        correct += (y_pred == y).sum().item()\n",
    "        total += x.size(0)\n",
    "\n",
    "        ys.extend(y.detach().cpu().tolist())\n",
    "        y_preds.extend(y_pred.detach().cpu().tolist())\n",
    "\n",
    "    # valid done\n",
    "    val_acc = correct / total\n",
    "    log_str = f\"Epoch {epoch+1}/{N_EPOCH} | train_loss={train_loss:.4f} | train_acc={train_acc:.3f} | val_acc={val_acc:.3f} | used GPU={gpu_used_mb()}MB\"\n",
    "    logging.info(log_str), print(log_str)\n",
    "    logging.info(classification_report(ys, y_preds))\n",
    "\n",
    "    if val_acc < train_acc and train_acc - val_acc > MAX_TOLERANCE_DELTA:\n",
    "        tolerance += 1\n",
    "    else:\n",
    "        tolerance = 0\n",
    "    \n",
    "    if tolerance > MAX_TOLERANCE:\n",
    "        print(f\"Overlearnig: Rolling back to {model_filename}\")\n",
    "        checkpoint = torch.load(\n",
    "            model_filename,\n",
    "            map_location=torch.device(device)\n",
    "        )\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        flag_rolledback = True\n",
    "        continue\n",
    "        \n",
    "    # —á–µ–∫–ø–æ–∏–Ω—Ç –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
    "    if val_acc > best_acc:\n",
    "        \n",
    "        model_filename = os.path.join(DRIVE_PATH, f\"model_acc{(1000*val_acc):03.0f}.pth\")\n",
    "        if not os.path.exists(model_filename):\n",
    "            best_acc = val_acc\n",
    "            checkpoint = {\n",
    "              'acc': val_acc,\n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }\n",
    "            torch.save(checkpoint, model_filename)\n",
    "            \n",
    "            flag_getbettermodel = True\n",
    "            continue\n",
    "    else:\n",
    "        if last_val_acc < val_acc :\n",
    "            # –µ—Å–ª–∏ –≤—Å—ë –µ—â—ë –µ—Å—Ç—å –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ –æ–±—É—á–µ–Ω–∏–∏\n",
    "            last_val_acc = val_acc\n",
    "            continue\n",
    "        \n",
    "        patience += 1\n",
    "        if patience > MAX_PATIENCE:\n",
    "            print(f\"no raise val_acc: Rolling back to {model_filename}\")\n",
    "            checkpoint = torch.load(\n",
    "                model_filename,\n",
    "                map_location=torch.device(device)\n",
    "            )\n",
    "            model.load_state_dict(checkpoint['model_state_dict'])\n",
    "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "            \n",
    "            flag_rolledback = True\n",
    "            continue\n",
    "\n",
    "finally:\n",
    "  # —Ä–µ–∑–µ—Ä–≤–Ω–æ–µ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞ –ª–æ–≥–æ–≤\n",
    "  time = datetime.now().strftime('%H%M%S')\n",
    "  # —Ñ–∞–π–ª –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è\n",
    "   #drive_log_name = f\"log_colab_{ time }.txt\"\n",
    "   #drive_log_path = os.path.join(DRIVE_PATH , drive_log_name)\n",
    "   #!cp \"{LOG_FILENAME}\" \"{drive_log_path}\"\n",
    "  # —Ç–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å\n",
    "  drive_log_name = f\"curent_model_{ time }.pth\"\n",
    "  drive_log_path = os.path.join(DRIVE_PATH , drive_log_name)\n",
    "  checkpoint = {\n",
    "    'acc': correct / total,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "  }\n",
    "  torch.save(checkpoint, drive_log_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ñ—ë—Å—Ç–∫–∞—è –ø–æ–ª–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ GPU –ø–∞–º—è—Ç–∏:  \n",
    "`nvidia-smi` —É–∑–Ω–∞—ë–º PID python –ø—Ä–æ—Ü–µ—Å—Å–∞  \n",
    "`kill <PID>`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7501.0\n",
      "7501.0\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "print(gpu_used_mb())\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(gpu_used_mb())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
